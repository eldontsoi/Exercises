{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-0a5ceed0c778>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-0a5ceed0c778>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    POST https://vision.googleapis.com/v1/images:annotate?key=YOUR_API_KEY\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "POST https://vision.googleapis.com/v1/images:annotate?key=YOUR_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-5e83573cda57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcloud\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mvision\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import io\n",
    "\n",
    "from google.cloud import vision\n",
    "\n",
    "\n",
    "# [START def_detect_faces]\n",
    "def detect_faces(path):\n",
    "    \"\"\"Detects faces in an image.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START migration_face_detection]\n",
    "    # [START migration_image_file]\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "    # [END migration_image_file]\n",
    "\n",
    "    response = client.face_detection(image=image)\n",
    "    faces = response.face_annotations\n",
    "\n",
    "    # Names of likelihood from google.cloud.vision.enums\n",
    "    likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE',\n",
    "                       'LIKELY', 'VERY_LIKELY')\n",
    "    print('Faces:')\n",
    "\n",
    "    for face in faces:\n",
    "        print('anger: {}'.format(likelihood_name[face.anger_likelihood]))\n",
    "        print('joy: {}'.format(likelihood_name[face.joy_likelihood]))\n",
    "        print('surprise: {}'.format(likelihood_name[face.surprise_likelihood]))\n",
    "\n",
    "        vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                    for vertex in face.bounding_poly.vertices])\n",
    "\n",
    "        print('face bounds: {}'.format(','.join(vertices)))\n",
    "    # [END migration_face_detection]\n",
    "# [END def_detect_faces]\n",
    "\n",
    "\n",
    "# [START def_detect_faces_uri]\n",
    "def detect_faces_uri(uri):\n",
    "    \"\"\"Detects faces in the file located in Google Cloud Storage or the web.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    # [START migration_image_uri]\n",
    "    image = vision.types.Image()\n",
    "    image.source.image_uri = uri\n",
    "    # [END migration_image_uri]\n",
    "\n",
    "    response = client.face_detection(image=image)\n",
    "    faces = response.face_annotations\n",
    "\n",
    "    # Names of likelihood from google.cloud.vision.enums\n",
    "    likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE',\n",
    "                       'LIKELY', 'VERY_LIKELY')\n",
    "    print('Faces:')\n",
    "\n",
    "    for face in faces:\n",
    "        print('anger: {}'.format(likelihood_name[face.anger_likelihood]))\n",
    "        print('joy: {}'.format(likelihood_name[face.joy_likelihood]))\n",
    "        print('surprise: {}'.format(likelihood_name[face.surprise_likelihood]))\n",
    "\n",
    "        vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                    for vertex in face.bounding_poly.vertices])\n",
    "\n",
    "        print('face bounds: {}'.format(','.join(vertices)))\n",
    "# [END def_detect_faces_uri]\n",
    "\n",
    "\n",
    "# [START def_detect_labels]\n",
    "def detect_labels(path):\n",
    "    \"\"\"Detects labels in the file.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START migration_label_detection]\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "    print('Labels:')\n",
    "\n",
    "    for label in labels:\n",
    "        print(label.description)\n",
    "    # [END migration_label_detection]\n",
    "# [END def_detect_labels]\n",
    "\n",
    "\n",
    "# [START def_detect_labels_uri]\n",
    "def detect_labels_uri(uri):\n",
    "    \"\"\"Detects labels in the file located in Google Cloud Storage or on the\n",
    "    Web.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.types.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.label_detection(image=image)\n",
    "    labels = response.label_annotations\n",
    "    print('Labels:')\n",
    "\n",
    "    for label in labels:\n",
    "        print(label.description)\n",
    "# [END def_detect_labels_uri]\n",
    "\n",
    "\n",
    "# [START def_detect_landmarks]\n",
    "def detect_landmarks(path):\n",
    "    \"\"\"Detects landmarks in the file.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START migration_landmark_detection]\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.landmark_detection(image=image)\n",
    "    landmarks = response.landmark_annotations\n",
    "    print('Landmarks:')\n",
    "\n",
    "    for landmark in landmarks:\n",
    "        print(landmark.description)\n",
    "        for location in landmark.locations:\n",
    "            lat_lng = location.lat_lng\n",
    "            print('Latitude {}'.format(lat_lng.latitude))\n",
    "            print('Longitude {}'.format(lat_lng.longitude))\n",
    "    # [END migration_landmark_detection]\n",
    "# [END def_detect_landmarks]\n",
    "\n",
    "\n",
    "# [START def_detect_landmarks_uri]\n",
    "def detect_landmarks_uri(uri):\n",
    "    \"\"\"Detects landmarks in the file located in Google Cloud Storage or on the\n",
    "    Web.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.types.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.landmark_detection(image=image)\n",
    "    landmarks = response.landmark_annotations\n",
    "    print('Landmarks:')\n",
    "\n",
    "    for landmark in landmarks:\n",
    "        print(landmark.description)\n",
    "# [END def_detect_landmarks_uri]\n",
    "\n",
    "\n",
    "# [START def_detect_logos]\n",
    "def detect_logos(path):\n",
    "    \"\"\"Detects logos in the file.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START migration_logo_detection]\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.logo_detection(image=image)\n",
    "    logos = response.logo_annotations\n",
    "    print('Logos:')\n",
    "\n",
    "    for logo in logos:\n",
    "        print(logo.description)\n",
    "    # [END migration_logo_detection]\n",
    "# [END def_detect_logos]\n",
    "\n",
    "\n",
    "# [START def_detect_logos_uri]\n",
    "def detect_logos_uri(uri):\n",
    "    \"\"\"Detects logos in the file located in Google Cloud Storage or on the Web.\n",
    "    \"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.types.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.logo_detection(image=image)\n",
    "    logos = response.logo_annotations\n",
    "    print('Logos:')\n",
    "\n",
    "    for logo in logos:\n",
    "        print(logo.description)\n",
    "# [END def_detect_logos_uri]\n",
    "\n",
    "\n",
    "# [START def_detect_safe_search]\n",
    "def detect_safe_search(path):\n",
    "    \"\"\"Detects unsafe features in the file.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START migration_safe_search_detection]\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.safe_search_detection(image=image)\n",
    "    safe = response.safe_search_annotation\n",
    "\n",
    "    # Names of likelihood from google.cloud.vision.enums\n",
    "    likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE',\n",
    "                       'LIKELY', 'VERY_LIKELY')\n",
    "    print('Safe search:')\n",
    "\n",
    "    print('adult: {}'.format(likelihood_name[safe.adult]))\n",
    "    print('medical: {}'.format(likelihood_name[safe.medical]))\n",
    "    print('spoofed: {}'.format(likelihood_name[safe.spoof]))\n",
    "    print('violence: {}'.format(likelihood_name[safe.violence]))\n",
    "    print('racy: {}'.format(likelihood_name[safe.racy]))\n",
    "    # [END migration_safe_search_detection]\n",
    "# [END def_detect_safe_search]\n",
    "\n",
    "\n",
    "# [START def_detect_safe_search_uri]\n",
    "def detect_safe_search_uri(uri):\n",
    "    \"\"\"Detects unsafe features in the file located in Google Cloud Storage or\n",
    "    on the Web.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.types.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.safe_search_detection(image=image)\n",
    "    safe = response.safe_search_annotation\n",
    "\n",
    "    # Names of likelihood from google.cloud.vision.enums\n",
    "    likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE',\n",
    "                       'LIKELY', 'VERY_LIKELY')\n",
    "    print('Safe search:')\n",
    "\n",
    "    print('adult: {}'.format(likelihood_name[safe.adult]))\n",
    "    print('medical: {}'.format(likelihood_name[safe.medical]))\n",
    "    print('spoofed: {}'.format(likelihood_name[safe.spoof]))\n",
    "    print('violence: {}'.format(likelihood_name[safe.violence]))\n",
    "    print('racy: {}'.format(likelihood_name[safe.racy]))\n",
    "# [END def_detect_safe_search_uri]\n",
    "\n",
    "\n",
    "# [START def_detect_text]\n",
    "def detect_text(path):\n",
    "    \"\"\"Detects text in the file.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START migration_text_detection]\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    print('Texts:')\n",
    "\n",
    "    for text in texts:\n",
    "        print('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "        vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                    for vertex in text.bounding_poly.vertices])\n",
    "\n",
    "        print('bounds: {}'.format(','.join(vertices)))\n",
    "    # [END migration_text_detection]\n",
    "# [END def_detect_text]\n",
    "\n",
    "\n",
    "# [START def_detect_text_uri]\n",
    "def detect_text_uri(uri):\n",
    "    \"\"\"Detects text in the file located in Google Cloud Storage or on the Web.\n",
    "    \"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.types.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.text_detection(image=image)\n",
    "    texts = response.text_annotations\n",
    "    print('Texts:')\n",
    "\n",
    "    for text in texts:\n",
    "        print('\\n\"{}\"'.format(text.description))\n",
    "\n",
    "        vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                    for vertex in text.bounding_poly.vertices])\n",
    "\n",
    "        print('bounds: {}'.format(','.join(vertices)))\n",
    "# [END def_detect_text_uri]\n",
    "\n",
    "\n",
    "# [START def_detect_properties]\n",
    "def detect_properties(path):\n",
    "    \"\"\"Detects image properties in the file.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START migration_image_properties]\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.image_properties(image=image)\n",
    "    props = response.image_properties_annotation\n",
    "    print('Properties:')\n",
    "\n",
    "    for color in props.dominant_colors.colors:\n",
    "        print('fraction: {}'.format(color.pixel_fraction))\n",
    "        print('\\tr: {}'.format(color.color.red))\n",
    "        print('\\tg: {}'.format(color.color.green))\n",
    "        print('\\tb: {}'.format(color.color.blue))\n",
    "        print('\\ta: {}'.format(color.color.alpha))\n",
    "    # [END migration_image_properties]\n",
    "# [END def_detect_properties]\n",
    "\n",
    "\n",
    "# [START def_detect_properties_uri]\n",
    "def detect_properties_uri(uri):\n",
    "    \"\"\"Detects image properties in the file located in Google Cloud Storage or\n",
    "    on the Web.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.types.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.image_properties(image=image)\n",
    "    props = response.image_properties_annotation\n",
    "    print('Properties:')\n",
    "\n",
    "    for color in props.dominant_colors.colors:\n",
    "        print('frac: {}'.format(color.pixel_fraction))\n",
    "        print('\\tr: {}'.format(color.color.red))\n",
    "        print('\\tg: {}'.format(color.color.green))\n",
    "        print('\\tb: {}'.format(color.color.blue))\n",
    "        print('\\ta: {}'.format(color.color.alpha))\n",
    "# [END def_detect_properties_uri]\n",
    "\n",
    "\n",
    "# [START def_detect_web]\n",
    "def detect_web(path):\n",
    "    \"\"\"Detects web annotations given an image.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START migration_web_detection]\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.web_detection(image=image)\n",
    "    annotations = response.web_detection\n",
    "\n",
    "    if annotations.best_guess_labels:\n",
    "        for label in annotations.best_guess_labels:\n",
    "            print('\\nBest guess label: {}'.format(label.label))\n",
    "\n",
    "    if annotations.pages_with_matching_images:\n",
    "        print('\\n{} Pages with matching images found:'.format(\n",
    "            len(annotations.pages_with_matching_images)))\n",
    "\n",
    "        for page in annotations.pages_with_matching_images:\n",
    "            print('\\n\\tPage url   : {}'.format(page.url))\n",
    "\n",
    "            if page.full_matching_images:\n",
    "                print('\\t{} Full Matches found: '.format(\n",
    "                       len(page.full_matching_images)))\n",
    "\n",
    "                for image in page.full_matching_images:\n",
    "                    print('\\t\\tImage url  : {}'.format(image.url))\n",
    "\n",
    "            if page.partial_matching_images:\n",
    "                print('\\t{} Partial Matches found: '.format(\n",
    "                       len(page.partial_matching_images)))\n",
    "\n",
    "                for image in page.partial_matching_images:\n",
    "                    print('\\t\\tImage url  : {}'.format(image.url))\n",
    "\n",
    "    if annotations.web_entities:\n",
    "        print('\\n{} Web entities found: '.format(\n",
    "            len(annotations.web_entities)))\n",
    "\n",
    "        for entity in annotations.web_entities:\n",
    "            print('\\n\\tScore      : {}'.format(entity.score))\n",
    "            print(u'\\tDescription: {}'.format(entity.description))\n",
    "\n",
    "    if annotations.visually_similar_images:\n",
    "        print('\\n{} visually similar images found:\\n'.format(\n",
    "            len(annotations.visually_similar_images)))\n",
    "\n",
    "        for image in annotations.visually_similar_images:\n",
    "            print('\\tImage url    : {}'.format(image.url))\n",
    "    # [END migration_web_detection]\n",
    "# [END def_detect_web]\n",
    "\n",
    "\n",
    "# [START def_detect_web_uri]\n",
    "def detect_web_uri(uri):\n",
    "    \"\"\"Detects web annotations in the file located in Google Cloud Storage.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.types.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.web_detection(image=image)\n",
    "    annotations = response.web_detection\n",
    "\n",
    "    if annotations.best_guess_labels:\n",
    "        for label in annotations.best_guess_labels:\n",
    "            print('\\nBest guess label: {}'.format(label.label))\n",
    "\n",
    "    if annotations.pages_with_matching_images:\n",
    "        print('\\n{} Pages with matching images found:'.format(\n",
    "            len(annotations.pages_with_matching_images)))\n",
    "\n",
    "        for page in annotations.pages_with_matching_images:\n",
    "            print('\\n\\tPage url   : {}'.format(page.url))\n",
    "\n",
    "            if page.full_matching_images:\n",
    "                print('\\t{} Full Matches found: '.format(\n",
    "                       len(page.full_matching_images)))\n",
    "\n",
    "                for image in page.full_matching_images:\n",
    "                    print('\\t\\tImage url  : {}'.format(image.url))\n",
    "\n",
    "            if page.partial_matching_images:\n",
    "                print('\\t{} Partial Matches found: '.format(\n",
    "                       len(page.partial_matching_images)))\n",
    "\n",
    "                for image in page.partial_matching_images:\n",
    "                    print('\\t\\tImage url  : {}'.format(image.url))\n",
    "\n",
    "    if annotations.web_entities:\n",
    "        print('\\n{} Web entities found: '.format(\n",
    "            len(annotations.web_entities)))\n",
    "\n",
    "        for entity in annotations.web_entities:\n",
    "            print('\\n\\tScore      : {}'.format(entity.score))\n",
    "            print(u'\\tDescription: {}'.format(entity.description))\n",
    "\n",
    "    if annotations.visually_similar_images:\n",
    "        print('\\n{} visually similar images found:\\n'.format(\n",
    "            len(annotations.visually_similar_images)))\n",
    "\n",
    "        for image in annotations.visually_similar_images:\n",
    "            print('\\tImage url    : {}'.format(image.url))\n",
    "# [END def_detect_web_uri]\n",
    "\n",
    "\n",
    "# [START vision_web_entities_include_geo_results]\n",
    "def web_entities_include_geo_results(path):\n",
    "    \"\"\"Detects web annotations given an image, using the geotag metadata\n",
    "    in the iamge to detect web entities.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    web_detection_params = vision.types.WebDetectionParams(\n",
    "        include_geo_results=True)\n",
    "    image_context = vision.types.ImageContext(\n",
    "        web_detection_params=web_detection_params)\n",
    "\n",
    "    response = client.web_detection(image=image, image_context=image_context)\n",
    "\n",
    "    for entity in response.web_detection.web_entities:\n",
    "        print('\\n\\tScore      : {}'.format(entity.score))\n",
    "        print(u'\\tDescription: {}'.format(entity.description))\n",
    "# [END vision_web_entities_include_geo_results]\n",
    "\n",
    "\n",
    "# [START vision_web_entities_include_geo_results_uri]\n",
    "def web_entities_include_geo_results_uri(uri):\n",
    "    \"\"\"Detects web annotations given an image in the file located in\n",
    "    Google Cloud Storage., using the geotag metadata in the iamge to\n",
    "    detect web entities.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    image = vision.types.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    web_detection_params = vision.types.WebDetectionParams(\n",
    "        include_geo_results=True)\n",
    "    image_context = vision.types.ImageContext(\n",
    "        web_detection_params=web_detection_params)\n",
    "\n",
    "    response = client.web_detection(image=image, image_context=image_context)\n",
    "\n",
    "    for entity in response.web_detection.web_entities:\n",
    "        print('\\n\\tScore      : {}'.format(entity.score))\n",
    "        print(u'\\tDescription: {}'.format(entity.description))\n",
    "# [END vision_web_entities_include_geo_results_uri]\n",
    "\n",
    "\n",
    "# [START def_detect_crop_hints]\n",
    "def detect_crop_hints(path):\n",
    "    \"\"\"Detects crop hints in an image.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START migration_crop_hints]\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    crop_hints_params = vision.types.CropHintsParams(aspect_ratios=[1.77])\n",
    "    image_context = vision.types.ImageContext(\n",
    "        crop_hints_params=crop_hints_params)\n",
    "\n",
    "    response = client.crop_hints(image=image, image_context=image_context)\n",
    "    hints = response.crop_hints_annotation.crop_hints\n",
    "\n",
    "    for n, hint in enumerate(hints):\n",
    "        print('\\nCrop Hint: {}'.format(n))\n",
    "\n",
    "        vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                    for vertex in hint.bounding_poly.vertices])\n",
    "\n",
    "        print('bounds: {}'.format(','.join(vertices)))\n",
    "    # [END migration_crop_hints]\n",
    "# [END def_detect_crop_hints]\n",
    "\n",
    "\n",
    "# [START def_detect_crop_hints_uri]\n",
    "def detect_crop_hints_uri(uri):\n",
    "    \"\"\"Detects crop hints in the file located in Google Cloud Storage.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.types.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    crop_hints_params = vision.types.CropHintsParams(aspect_ratios=[1.77])\n",
    "    image_context = vision.types.ImageContext(\n",
    "        crop_hints_params=crop_hints_params)\n",
    "\n",
    "    response = client.crop_hints(image=image, image_context=image_context)\n",
    "    hints = response.crop_hints_annotation.crop_hints\n",
    "\n",
    "    for n, hint in enumerate(hints):\n",
    "        print('\\nCrop Hint: {}'.format(n))\n",
    "\n",
    "        vertices = (['({},{})'.format(vertex.x, vertex.y)\n",
    "                    for vertex in hint.bounding_poly.vertices])\n",
    "\n",
    "        print('bounds: {}'.format(','.join(vertices)))\n",
    "# [END def_detect_crop_hints_uri]\n",
    "\n",
    "\n",
    "# [START def_detect_document]\n",
    "def detect_document(path):\n",
    "    \"\"\"Detects document features in an image.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "\n",
    "    # [START migration_document_text_detection]\n",
    "    with io.open(path, 'rb') as image_file:\n",
    "        content = image_file.read()\n",
    "\n",
    "    image = vision.types.Image(content=content)\n",
    "\n",
    "    response = client.document_text_detection(image=image)\n",
    "\n",
    "    for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            print('\\nBlock confidence: {}\\n'.format(block.confidence))\n",
    "\n",
    "            for paragraph in block.paragraphs:\n",
    "                print('Paragraph confidence: {}'.format(\n",
    "                    paragraph.confidence))\n",
    "\n",
    "                for word in paragraph.words:\n",
    "                    word_text = ''.join([\n",
    "                        symbol.text for symbol in word.symbols\n",
    "                    ])\n",
    "                    print('Word text: {} (confidence: {})'.format(\n",
    "                        word_text, word.confidence))\n",
    "\n",
    "                    for symbol in word.symbols:\n",
    "                        print('\\tSymbol: {} (confidence: {})'.format(\n",
    "                            symbol.text, symbol.confidence))\n",
    "    # [END migration_document_text_detection]\n",
    "# [END def_detect_document]\n",
    "\n",
    "\n",
    "# [START def_detect_document_uri]\n",
    "def detect_document_uri(uri):\n",
    "    \"\"\"Detects document features in the file located in Google Cloud\n",
    "    Storage.\"\"\"\n",
    "    client = vision.ImageAnnotatorClient()\n",
    "    image = vision.types.Image()\n",
    "    image.source.image_uri = uri\n",
    "\n",
    "    response = client.document_text_detection(image=image)\n",
    "\n",
    "    for page in response.full_text_annotation.pages:\n",
    "        for block in page.blocks:\n",
    "            print('\\nBlock confidence: {}\\n'.format(block.confidence))\n",
    "\n",
    "            for paragraph in block.paragraphs:\n",
    "                print('Paragraph confidence: {}'.format(\n",
    "                    paragraph.confidence))\n",
    "\n",
    "                for word in paragraph.words:\n",
    "                    word_text = ''.join([\n",
    "                        symbol.text for symbol in word.symbols\n",
    "                    ])\n",
    "                    print('Word text: {} (confidence: {})'.format(\n",
    "                        word_text, word.confidence))\n",
    "\n",
    "                    for symbol in word.symbols:\n",
    "                        print('\\tSymbol: {} (confidence: {})'.format(\n",
    "                            symbol.text, symbol.confidence))\n",
    "# [END def_detect_document_uri]\n",
    "\n",
    "\n",
    "def run_local(args):\n",
    "    if args.command == 'faces':\n",
    "        detect_faces(args.path)\n",
    "    elif args.command == 'labels':\n",
    "        detect_labels(args.path)\n",
    "    elif args.command == 'landmarks':\n",
    "        detect_landmarks(args.path)\n",
    "    elif args.command == 'text':\n",
    "        detect_text(args.path)\n",
    "    elif args.command == 'logos':\n",
    "        detect_logos(args.path)\n",
    "    elif args.command == 'safe-search':\n",
    "        detect_safe_search(args.path)\n",
    "    elif args.command == 'properties':\n",
    "        detect_properties(args.path)\n",
    "    elif args.command == 'web':\n",
    "        detect_web(args.path)\n",
    "    elif args.command == 'crophints':\n",
    "        detect_crop_hints(args.path)\n",
    "    elif args.command == 'document':\n",
    "        detect_document(args.path)\n",
    "    elif args.command == 'web-geo':\n",
    "        web_entities_include_geo_results(args.path)\n",
    "\n",
    "\n",
    "def run_uri(args):\n",
    "    if args.command == 'text-uri':\n",
    "        detect_text_uri(args.uri)\n",
    "    elif args.command == 'faces-uri':\n",
    "        detect_faces_uri(args.uri)\n",
    "    elif args.command == 'labels-uri':\n",
    "        detect_labels_uri(args.uri)\n",
    "    elif args.command == 'landmarks-uri':\n",
    "        detect_landmarks_uri(args.uri)\n",
    "    elif args.command == 'logos-uri':\n",
    "        detect_logos_uri(args.uri)\n",
    "    elif args.command == 'safe-search-uri':\n",
    "        detect_safe_search_uri(args.uri)\n",
    "    elif args.command == 'properties-uri':\n",
    "        detect_properties_uri(args.uri)\n",
    "    elif args.command == 'web-uri':\n",
    "        detect_web_uri(args.uri)\n",
    "    elif args.command == 'crophints-uri':\n",
    "        detect_crop_hints_uri(args.uri)\n",
    "    elif args.command == 'document-uri':\n",
    "        detect_document_uri(args.uri)\n",
    "    elif args.command == 'web-geo-uri':\n",
    "        web_entities_include_geo_results_uri(args.uri)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description=__doc__,\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter)\n",
    "    subparsers = parser.add_subparsers(dest='command')\n",
    "\n",
    "    detect_faces_parser = subparsers.add_parser(\n",
    "        'faces', help=detect_faces.__doc__)\n",
    "    detect_faces_parser.add_argument('path')\n",
    "\n",
    "    faces_file_parser = subparsers.add_parser(\n",
    "        'faces-uri', help=detect_faces_uri.__doc__)\n",
    "    faces_file_parser.add_argument('uri')\n",
    "\n",
    "    detect_labels_parser = subparsers.add_parser(\n",
    "        'labels', help=detect_labels.__doc__)\n",
    "    detect_labels_parser.add_argument('path')\n",
    "\n",
    "    labels_file_parser = subparsers.add_parser(\n",
    "        'labels-uri', help=detect_labels_uri.__doc__)\n",
    "    labels_file_parser.add_argument('uri')\n",
    "\n",
    "    detect_landmarks_parser = subparsers.add_parser(\n",
    "        'landmarks', help=detect_landmarks.__doc__)\n",
    "    detect_landmarks_parser.add_argument('path')\n",
    "\n",
    "    landmark_file_parser = subparsers.add_parser(\n",
    "        'landmarks-uri', help=detect_landmarks_uri.__doc__)\n",
    "    landmark_file_parser.add_argument('uri')\n",
    "\n",
    "    detect_text_parser = subparsers.add_parser(\n",
    "        'text', help=detect_text.__doc__)\n",
    "    detect_text_parser.add_argument('path')\n",
    "\n",
    "    text_file_parser = subparsers.add_parser(\n",
    "        'text-uri', help=detect_text_uri.__doc__)\n",
    "    text_file_parser.add_argument('uri')\n",
    "\n",
    "    detect_logos_parser = subparsers.add_parser(\n",
    "        'logos', help=detect_logos.__doc__)\n",
    "    detect_logos_parser.add_argument('path')\n",
    "\n",
    "    logos_file_parser = subparsers.add_parser(\n",
    "        'logos-uri', help=detect_logos_uri.__doc__)\n",
    "    logos_file_parser.add_argument('uri')\n",
    "\n",
    "    safe_search_parser = subparsers.add_parser(\n",
    "        'safe-search', help=detect_safe_search.__doc__)\n",
    "    safe_search_parser.add_argument('path')\n",
    "\n",
    "    safe_search_file_parser = subparsers.add_parser(\n",
    "        'safe-search-uri',\n",
    "        help=detect_safe_search_uri.__doc__)\n",
    "    safe_search_file_parser.add_argument('uri')\n",
    "\n",
    "    properties_parser = subparsers.add_parser(\n",
    "        'properties', help=detect_properties.__doc__)\n",
    "    properties_parser.add_argument('path')\n",
    "\n",
    "    properties_file_parser = subparsers.add_parser(\n",
    "        'properties-uri',\n",
    "        help=detect_properties_uri.__doc__)\n",
    "    properties_file_parser.add_argument('uri')\n",
    "\n",
    "    # 1.1 Vision features\n",
    "    web_parser = subparsers.add_parser(\n",
    "        'web', help=detect_web.__doc__)\n",
    "    web_parser.add_argument('path')\n",
    "\n",
    "    web_uri_parser = subparsers.add_parser(\n",
    "        'web-uri',\n",
    "        help=detect_web_uri.__doc__)\n",
    "    web_uri_parser.add_argument('uri')\n",
    "\n",
    "    web_geo_parser = subparsers.add_parser(\n",
    "        'web-geo', help=web_entities_include_geo_results.__doc__)\n",
    "    web_geo_parser.add_argument('path')\n",
    "\n",
    "    web_geo_uri_parser = subparsers.add_parser(\n",
    "        'web-geo-uri',\n",
    "        help=web_entities_include_geo_results_uri.__doc__)\n",
    "    web_geo_uri_parser.add_argument('uri')\n",
    "\n",
    "    crop_hints_parser = subparsers.add_parser(\n",
    "        'crophints', help=detect_crop_hints.__doc__)\n",
    "    crop_hints_parser.add_argument('path')\n",
    "\n",
    "    crop_hints_uri_parser = subparsers.add_parser(\n",
    "        'crophints-uri', help=detect_crop_hints_uri.__doc__)\n",
    "    crop_hints_uri_parser.add_argument('uri')\n",
    "\n",
    "    document_parser = subparsers.add_parser(\n",
    "        'document', help=detect_document.__doc__)\n",
    "    document_parser.add_argument('path')\n",
    "\n",
    "    document_uri_parser = subparsers.add_parser(\n",
    "        'document-uri', help=detect_document_uri.__doc__)\n",
    "    document_uri_parser.add_argument('uri')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    if ('uri' in args.command):\n",
    "        run_uri(args)\n",
    "    else:\n",
    "        run_local(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
